{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rana-Shukor/vector1/blob/main/Copy_of_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAYNStAxDX02",
        "outputId": "c17b8e21-13ec-481c-b6b1-4255681ac13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Exploring GPT-2 Architecture and Parameters**\n",
        "\n",
        "### **Introduction**\n",
        "\n",
        "In this exercise, we will explore GPT-2, a state-of-the-art language model known for its ability to generate coherent and creative text. We will examine the model's architecture, count its parameters, and investigate how changing the temperature parameter affects text generation.\n",
        "\n",
        "### **Objectives**\n",
        "1. Load the GPT-2 model.\n",
        "2. Count and display the total number of parameters.\n",
        "3. Generate text with different temperatures to observe the effect on creativity and randomness.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "65B2l4jbJL8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1: Load the GPT-2 Model**\n",
        "\n",
        "We will start by loading the smallest version of GPT-2. This version is efficient and easy to work with, making it ideal for exploring the model's functionality.\n"
      ],
      "metadata": {
        "id": "hyGqJKMVJaoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the pre-trained GPT-2 model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "print(\"GPT-2 model loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "bbCMKO0TJMn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2: Count the Number of Parameters**\n",
        "\n",
        "Let’s find out how many parameters the GPT-2 model contains. This information will help us understand the model's complexity and capacity.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pMLWeFTkJbxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Count the total number of parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Print the result\n",
        "print(f\"Total number of parameters in GPT-2: {total_params:,}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heza8C59Jb8M",
        "outputId": "575a71f9-e9ea-4b7f-a26f-d6eec742b1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in GPT-2: 124,439,808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3: Test Text Generation with Different Temperatures**\n",
        "\n",
        "The `temperature` parameter controls the randomness of the generated text. A low temperature makes the output more deterministic, while a high temperature introduces more randomness. We’ll test different temperature values to see how they affect the text generation.\n",
        "\n"
      ],
      "metadata": {
        "id": "gw3gsyfEJcP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function to generate text with temperature and attention mask\n",
        "def generate_text_with_attention_mask(temperature):\n",
        "    # Input text for the model to generate from\n",
        "    input_text = \"my hole life was \"\n",
        "\n",
        "    # Tokenize the input text\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Create attention mask (1s for real tokens, 0s for padding tokens)\n",
        "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
        "\n",
        "    # Generate text with the specified temperature\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=50,\n",
        "        temperature=temperature,\n",
        "        do_sample=True,\n",
        "        attention_mask=attention_mask,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode and return the generated text\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Test different temperature values\n",
        "temperatures = [0.1, 0.3, 0.6, 1.0]\n",
        "\n",
        "for temp in temperatures:\n",
        "    print(f\"\\nTemperature: {temp}\")\n",
        "    print(generate_text_with_attention_mask(temp))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI6h3YjVJcYl",
        "outputId": "e3c75e53-742f-426c-f956-02440fc76f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Temperature: 0.1\n",
            "my hole life was  a little bit more fun than I thought it would be. I was able to get a little more out of my life and I'm glad I did. I'm glad I did. I'm glad I did. I\n",
            "\n",
            "Temperature: 0.3\n",
            "my hole life was  in the sky, and I was a little bit scared. I was just a little bit scared.\n",
            "I was a little bit scared. I was a little bit scared. I was a little bit scared.\n",
            "I\n",
            "\n",
            "Temperature: 0.6\n",
            "my hole life was  very good! I am still very happy with my life as I am now in my 30's. I love eating and I want to do more. I am looking forward to the next month and I am looking forward to\n",
            "\n",
            "Temperature: 1.0\n",
            "my hole life was _______ on the moon, that it was not so bad until he left the land, and that he returned to earth a week after that on November 12, 1723, when his body was discovered, there was an accident of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GkPyVlhVQFTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Explanation:\n",
        "- **`attention_mask`**: An attention mask is created with all ones because GPT-2 does not use padding tokens in its architecture. However, it's still good practice to include it.\n",
        "- **`pad_token_id`**: Set to `tokenizer.eos_token_id` to handle open-end generation properly, as GPT-2 uses EOS tokens for indicating the end of sequences.\n",
        "\n",
        " This code snippet ensures that you handle the attention mask and padding token ID correctly when generating text with GPT-2. This approach helps avoid unexpected behavior and improves the reliability of the text generation results.\n",
        "\n"
      ],
      "metadata": {
        "id": "YjcwxACfJcge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Exploring Hugging Face Pipelines**\n",
        "\n",
        "In this exercise, you will work with two Hugging Face pipelines to perform different NLP tasks. You will also have the opportunity to explore additional pipelines on your own.\n",
        "\n",
        "#### **1. Sentiment Analysis Pipeline**\n",
        "\n",
        "The sentiment analysis pipeline allows you to determine the sentiment (positive, negative, or neutral) of a given piece of text.\n",
        "\n"
      ],
      "metadata": {
        "id": "CYooBPeQVwRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1:**\n",
        "- Test the sentiment analysis pipeline with different texts, such as product reviews or social media comments.\n",
        "- Analyze how the sentiment of various texts is classified.\n",
        "# New Section"
      ],
      "metadata": {
        "id": "wsKck0TxWOGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the transformers library if you haven't already\n",
        "!pip install transformers\n",
        "\n",
        "# Import necessary libraries\n",
        "from transformers import pipeline\n",
        "\n",
        "# Create the sentiment analysis pipeline\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# List of texts to analyze\n",
        "texts = [\n",
        "    \"I absolutely love this product! It works great and exceeded my expectations.\",\n",
        "    \"This is the worst purchase I've ever made. Totally regret it.\",\n",
        "    \"The service was okay, nothing special, but it wasn't terrible either.\",\n",
        "    \"I feel neutral about this item; it's just average.\",\n",
        "    \"Fantastic experience! Would highly recommend to everyone.\",\n",
        "    \"I hate this! It's a complete waste of money.\"\n",
        "]\n",
        "\n",
        "# Analyze sentiment for each text and print results\n",
        "for text in texts:\n",
        "    result = sentiment_pipeline(text)\n",
        "    print(f\"Text: {text}\\nSentiment: {result[0]['label']}, Score: {result[0]['score']:.4f}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiNQhtWWV2XJ",
        "outputId": "f64d1b5e-4fc1-48a7-cc4a-1f9e1d23c49a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I absolutely love this product! It works great and exceeded my expectations.\n",
            "Sentiment: POSITIVE, Score: 0.9999\n",
            "\n",
            "Text: This is the worst purchase I've ever made. Totally regret it.\n",
            "Sentiment: NEGATIVE, Score: 0.9998\n",
            "\n",
            "Text: The service was okay, nothing special, but it wasn't terrible either.\n",
            "Sentiment: NEGATIVE, Score: 0.9191\n",
            "\n",
            "Text: I feel neutral about this item; it's just average.\n",
            "Sentiment: NEGATIVE, Score: 0.9900\n",
            "\n",
            "Text: Fantastic experience! Would highly recommend to everyone.\n",
            "Sentiment: POSITIVE, Score: 0.9999\n",
            "\n",
            "Text: I hate this! It's a complete waste of money.\n",
            "Sentiment: NEGATIVE, Score: 0.9998\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2:**\n",
        "\n",
        "#### **Image-to-Text (Captioning) Pipeline**\n",
        "\n",
        "The image-to-text pipeline generates captions for images. For this exercise, you will need to find and use an image-to-text pipeline from Hugging Face.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. **Search for an Image-to-Text Pipeline:**\n",
        "   - Go to the Hugging Face Model Hub.\n",
        "   - Search for an image-to-text model, such as `Salesforce/blip-image-captioning-base` or similar.\n",
        "\n",
        "2. **Set Up the Pipeline:**\n",
        "   - Use the model you found to create an image-to-text pipeline.\n",
        "\n",
        "3. **Generate Captions:**\n",
        "   - Test the pipeline by providing images and observing the generated captions."
      ],
      "metadata": {
        "id": "PB-mfPcBWJcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install torch torchvision\n",
        "!pip install Pillow  # For image processing\n",
        "\n",
        "# Import necessary libraries\n",
        "import requests\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "# Load the processor and model from Hugging Face\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "# Function to generate a caption for an image\n",
        "def generate_caption(image_path):\n",
        "    # Open the image\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Preprocess the image\n",
        "    inputs = processor(image, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate caption\n",
        "    output = model.generate(**inputs)\n",
        "    caption = processor.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    return caption\n",
        "\n",
        "#Import the drive module from google.colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Update image directory path to point to your images in Google Drive\n",
        "image_directory = \"/content/drive/MyDrive/images\" # Update 'images' to the actual folder name\n",
        "# Example usage\n",
        "image_paths = [\n",
        "    \"/content/drive/MyDrive/images/imag1.jpg\",  # Replace with the actual path to your images\n",
        "    \"/content/drive/MyDrive/images/image2.jpg\",\n",
        "]\n",
        "\n",
        "# Generate captions for each image\n",
        "for img_path in image_paths:\n",
        "    caption = generate_caption(img_path)\n",
        "    print(f\"Image: {img_path}\\nCaption: {caption}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01Cqd2o_x39V",
        "outputId": "5a6c61d5-9326-4472-95d8-f81c463351db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: /content/drive/MyDrive/images/imag1.jpg\n",
            "Caption: a cat with a green background\n",
            "\n",
            "Image: /content/drive/MyDrive/images/image2.jpg\n",
            "Caption: a red rose with green leaves on a white background\n",
            "\n"
          ]
        }
      ]
    }
  ]
}