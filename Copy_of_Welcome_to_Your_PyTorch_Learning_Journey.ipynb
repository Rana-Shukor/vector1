{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rana-Shukor/vector1/blob/main/Copy_of_Welcome_to_Your_PyTorch_Learning_Journey.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLW4LJef6YEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to Your PyTorch Learning Journey\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook is designed to introduce you to the fundamentals of PyTorch, a powerful and flexible deep learning framework. By working through this notebook, you'll gain hands-on experience in building and training neural networks, a core skill in machine learning and artificial intelligence.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- **PyTorch Basics:** You'll start by exploring the basic building blocks of PyTorch, including tensors, autograd, and neural network modules.\n",
        "- **Building a Simple Neural Network:** You'll implement a simple feedforward neural network from scratch using PyTorch and learn how to train it on synthetic data.\n",
        "- **Training Loops and Optimization:** You'll understand how to implement the training loop, calculate loss, and update the model's parameters using gradient descent.\n",
        "\n",
        "## Example and Guide\n",
        "\n",
        "As you progress through this notebook, you'll find examples and explanations that will help you understand each concept. Code snippets are provided to demonstrate how to use PyTorch for various tasks. Follow along with the code, and feel free to modify it to see how different changes affect the outcome.\n",
        "\n",
        "## The Assignment\n",
        "\n",
        "After you've familiarized yourself with the basics, you'll be given an assignment to apply what you've learned to a real-world dataset: the MNIST dataset. This assignment will challenge you to build, train, and evaluate a neural network that can classify handwritten digits.\n",
        "\n",
        "The assignment is designed to consolidate your learning and give you practical experience with a common deep learning task. If you're up for an additional challenge, you can also explore more advanced architectures as a bonus.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Let's get started!\n"
      ],
      "metadata": {
        "id": "ttQxXTM35q3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "MN_pM7-r3Hal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Neural Network Model\n",
        "\n",
        "Here, we define a simple neural network class `SimpleNet` using PyTorch's `nn.Module`. This network consists of four linear layers with ReLU activations applied after each layer, except the final output layer.\n"
      ],
      "metadata": {
        "id": "SQLaiujf3eJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, hidden_size1, hidden_size2):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.layer1 = nn.Linear(1, hidden_size1)\n",
        "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.layer3 = nn.Linear(hidden_size2, hidden_size2)\n",
        "        self.layer4 = nn.Linear(hidden_size2, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x = self.layer4(x)\n",
        "        return x\n",
        "\n",
        "# Example of usage:\n",
        "# model = SimpleNet(hidden_size1=10, hidden_size2=5)\n",
        "# input = torch.randn(1, 1)  # Example input tensor\n",
        "# output = model(input)\n",
        "# print(output)\n"
      ],
      "metadata": {
        "id": "p6ihTRHn3hyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Model Wrapper Class\n",
        "\n",
        "The `ModelWrapper` class is used to encapsulate the model, loss function, and optimizer. This allows for easier management of the forward and backward passes during training.\n"
      ],
      "metadata": {
        "id": "mZtj09-y3oFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelWrapper:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.model(inputs)\n",
        "\n",
        "    def backward(self, loss):\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n"
      ],
      "metadata": {
        "id": "YXVThKjs3Ib4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Synthetic Data\n",
        "\n",
        "In this section, we define a function to generate synthetic data. The data has a linear relationship with added noise, and the target variable `y` is cubed to introduce non-linearity.\n"
      ],
      "metadata": {
        "id": "VGElY9dS3yR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(num_samples):\n",
        "    x = torch.randn(num_samples, 1)\n",
        "    y = 0.5 * x + 0.1 * torch.randn(num_samples, 1)  # Create correlation\n",
        "    y = y**3  # Raise y to cubic power\n",
        "    return x, y\n"
      ],
      "metadata": {
        "id": "5t4jAbjA31Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the Model, Loss Function, and Optimizer\n",
        "\n",
        "Here, we initialize the `SimpleNet` model with specified hidden layer sizes. We also define the Mean Squared Error (MSE) loss function and the Adam optimizer with a learning rate of 0.01.\n"
      ],
      "metadata": {
        "id": "ZIiqnqUR33Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size1 = 32\n",
        "hidden_size2 = 32\n",
        "\n",
        "model = SimpleNet(hidden_size1, hidden_size2)\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "wrapper = ModelWrapper(model, loss_fn, optimizer)\n"
      ],
      "metadata": {
        "id": "C6Qx0Sbp37Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model\n",
        "\n",
        "This cell contains the training loop, where the model is trained for a specified number of epochs. During each epoch, the forward and backward passes are performed, and the loss is printed every two epochs.\n"
      ],
      "metadata": {
        "id": "_OFbuv7h4Cu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "num_samples = 100\n",
        "x, y = generate_data(num_samples)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Explicit forward pass\n",
        "    outputs = wrapper.forward(x)\n",
        "    loss = loss_fn(outputs, y)\n",
        "\n",
        "    # Explicit backward pass\n",
        "    wrapper.backward(loss)\n",
        "\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4Wm2qaH39lt",
        "outputId": "6ebe3219-b7b1-42bf-9c4d-fd0ac4c3ec7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.0250\n",
            "Epoch [4/10], Loss: 0.0224\n",
            "Epoch [6/10], Loss: 0.0205\n",
            "Epoch [8/10], Loss: 0.0202\n",
            "Epoch [10/10], Loss: 0.0199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot the Results with Seaborn\n",
        "\n",
        "In this optional cell, we use Seaborn to visualize the original data and the model's predictions after training. Seaborn provides a more visually appealing style to the plots.\n"
      ],
      "metadata": {
        "id": "I78O15_B4MOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set seaborn style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Assume model, x, and y are already defined and x is your input tensor\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Disable gradient calculation\n",
        "with torch.no_grad():\n",
        "    predicted = model(x).detach().numpy()\n",
        "\n",
        "# Create a scatter plot of the original data\n",
        "sns.scatterplot(x=x.numpy().flatten(), y=y.numpy().flatten(), color='red', label='Original data')\n",
        "\n",
        "# Create a line plot of the model's predictions\n",
        "sns.lineplot(x=x.numpy().flatten(), y=predicted.flatten(), color='blue', label='Fitted line')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Model Predictions vs. Original Data')\n",
        "plt.xlabel('Input (x)')\n",
        "plt.ylabel('Output (y)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "___zXQa22ugn",
        "outputId": "77b1d43e-4401-4b13-c393-5f21c239f88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1ab812f9b16c>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Set model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Disable gradient calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Next Task: Train a Neural Network on the MNIST Dataset\n",
        "\n",
        "Now that you've explored the basics of PyTorch and built a simple model, it's time to apply your knowledge to a more practical example. A common and classic task in deep learning is to train a model on the MNIST dataset, which contains handwritten digits.\n",
        "\n",
        "## Steps to Follow:\n",
        "\n",
        "1. **Download and Prepare the MNIST Dataset:**\n",
        "   - Use PyTorch's `torchvision` library to download and preprocess the MNIST dataset.\n",
        "\n",
        "2. **Define a Neural Network:**\n",
        "   - Create a simple neural network that is suitable for classifying the 28x28 pixel images of handwritten digits.\n",
        "\n",
        "3. **Train the Model:**\n",
        "   - Implement the training loop, train the model on the MNIST dataset, and monitor the training loss.\n",
        "   - Use the trained model to make predictions on the test dataset.\n",
        "\n",
        "4. **Evaluate and Visualize Results:**\n",
        "   - Evaluate the model's performance on the test dataset and visualize some of the predictions.\n",
        "\n",
        "## Helpful Tips:\n",
        "\n",
        "- **Start Simple:** Focus on building a basic neural network architecture, such as a few fully connected layers.\n",
        "- **Experiment:** Try different optimizers, learning rates, and network architectures to see how they affect performance.\n",
        "- **Visualize:** Use `seaborn` or `matplotlib` to visualize the loss over time and the model's predictions.\n",
        "\n",
        "## Bonus (Optional):\n",
        "\n",
        "If you're feeling adventurous, you can try implementing a Convolutional Neural Network (CNN) for this task as an additional challenge. CNNs are particularly well-suited for image data and may improve your model's performance.\n",
        "\n",
        "## Need Help?\n",
        "\n",
        "If you need help getting started, feel free to ask questions, and I'll guide you through the process!\n"
      ],
      "metadata": {
        "id": "ZQoX7gK55VfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Download and Prepare the MNIST Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# Step 2: Define a Neural Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # First fully connected layer\n",
        "        self.fc2 = nn.Linear(128, 64)       # Second fully connected layer\n",
        "        self.fc3 = nn.Linear(64, 10)        # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the input tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Step 3: Train the Model\n",
        "model = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Step 4: Evaluate and Visualize Results\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')\n",
        "\n",
        "# Visualize some predictions\n",
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(example_data)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.tight_layout()\n",
        "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "    plt.title(f\"Prediction: {output.data.max(1, keepdim=True)[1][i].item()}\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Md0zv5MoX0dN",
        "outputId": "72aa4637-4e64-4c43-8e86-e7a1f2783f06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 52173048.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1851265.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 13730888.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2439560.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3174275370108198\n",
            "Epoch 2, Loss: 0.11408259926923811\n",
            "Epoch 3, Loss: 0.07768425989949675\n",
            "Epoch 4, Loss: 0.05824597531766779\n",
            "Epoch 5, Loss: 0.04504476029881096\n",
            "Epoch 6, Loss: 0.03493890396035366\n",
            "Epoch 7, Loss: 0.02829883431179026\n",
            "Epoch 8, Loss: 0.02158000177506711\n",
            "Epoch 9, Loss: 0.01638097787347398\n",
            "Epoch 10, Loss: 0.01280639520058518\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 97.74%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}